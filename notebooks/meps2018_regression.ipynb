{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eed490-0595-4838-b3d2-bbaf1a7c3949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9997d697-97c3-4983-8d10-bdd599db18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from heteroscedastic import BetaGaussianMLP, BetaGaussianLM, _radius, BetaGaussianQuad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfe6a50-b308-4747-8e8e-8fb9ebcf1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pd.read_csv('../data/MEPS_2018_house.csv')\n",
    "# df_test_all = pd.read_csv('../data/MEPS_2018_house.csv')\n",
    "# df_conf_all = pd.read_csv('../data/MEPS_2018_house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84fa70e-0ffd-448d-b60c-a6ff2832c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUPERSID</th>\n",
       "      <th>VARPSU</th>\n",
       "      <th>VARSTR</th>\n",
       "      <th>PERWT18F</th>\n",
       "      <th>PANEL</th>\n",
       "      <th>ADFLST42</th>\n",
       "      <th>AGE42X</th>\n",
       "      <th>AGELAST</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RACETHX</th>\n",
       "      <th>...</th>\n",
       "      <th>POVCAT18</th>\n",
       "      <th>POVLEV18</th>\n",
       "      <th>RTHLTH42</th>\n",
       "      <th>HAVEUS42</th>\n",
       "      <th>REGION42</th>\n",
       "      <th>TOTEXP18</th>\n",
       "      <th>HIBPDX</th>\n",
       "      <th>DIABDX_M18</th>\n",
       "      <th>ADBMI42</th>\n",
       "      <th>ADRNK542</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2290001101</td>\n",
       "      <td>1</td>\n",
       "      <td>2035</td>\n",
       "      <td>19667.668164</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>190.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2368</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2290001102</td>\n",
       "      <td>1</td>\n",
       "      <td>2035</td>\n",
       "      <td>18188.857143</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>190.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2040</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2290002101</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>3566.790451</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>163.92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2290002102</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>3879.757853</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>163.92</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2290002103</td>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>2707.394725</td>\n",
       "      <td>22</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>163.92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30456</th>\n",
       "      <td>2329684102</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>10560.396146</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>313.22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14660</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30457</th>\n",
       "      <td>2329685101</td>\n",
       "      <td>3</td>\n",
       "      <td>2076</td>\n",
       "      <td>6838.076209</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>457.79</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2439</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30458</th>\n",
       "      <td>2329687101</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>10603.950677</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>325.92</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17820</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30459</th>\n",
       "      <td>2329687102</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>15328.727238</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>325.92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30460</th>\n",
       "      <td>2329687103</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>19826.955373</td>\n",
       "      <td>23</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>325.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>529</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30461 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DUPERSID  VARPSU  VARSTR      PERWT18F  PANEL  ADFLST42  AGE42X  \\\n",
       "0      2290001101       1    2035  19667.668164     22         2      26   \n",
       "1      2290001102       1    2035  18188.857143     22         1      25   \n",
       "2      2290002101       2    2048   3566.790451     22         2      33   \n",
       "3      2290002102       2    2048   3879.757853     22         2      39   \n",
       "4      2290002103       2    2048   2707.394725     22        -1      11   \n",
       "...           ...     ...     ...           ...    ...       ...     ...   \n",
       "30456  2329684102       1    2003  10560.396146     23         2      65   \n",
       "30457  2329685101       3    2076   6838.076209     23         1      68   \n",
       "30458  2329687101       1    2072  10603.950677     23         1      33   \n",
       "30459  2329687102       1    2072  15328.727238     23         2      31   \n",
       "30460  2329687103       1    2072  19826.955373     23        -1       3   \n",
       "\n",
       "       AGELAST  SEX  RACETHX  ...  POVCAT18  POVLEV18  RTHLTH42  HAVEUS42  \\\n",
       "0           27    2        2  ...         3    190.31         2         1   \n",
       "1           25    1        2  ...         3    190.31         2         1   \n",
       "2           34    2        1  ...         3    163.92         3         1   \n",
       "3           39    1        1  ...         3    163.92         3         2   \n",
       "4           11    1        1  ...         3    163.92         3         1   \n",
       "...        ...  ...      ...  ...       ...       ...       ...       ...   \n",
       "30456       66    1        2  ...         4    313.22         3         1   \n",
       "30457       69    2        3  ...         5    457.79         3         1   \n",
       "30458       33    2        2  ...         4    325.92         4         1   \n",
       "30459       32    1        2  ...         4    325.92         2         1   \n",
       "30460        4    2        2  ...         4    325.92         1         1   \n",
       "\n",
       "       REGION42  TOTEXP18  HIBPDX  DIABDX_M18  ADBMI42  ADRNK542  \n",
       "0             2      2368       2           2     21.4        -1  \n",
       "1             2      2040       2           2     30.6         1  \n",
       "2             2       173       2           2     28.2        -1  \n",
       "3             2         0       2           2     28.7         2  \n",
       "4             2       103      -1           2     -1.0        -1  \n",
       "...         ...       ...     ...         ...      ...       ...  \n",
       "30456         3     14660       1           2     31.0         1  \n",
       "30457         3      2439       1           2     45.7        -1  \n",
       "30458         4     17820       2           2     29.2        -1  \n",
       "30459         4        90       2           2     27.3         1  \n",
       "30460         4       529      -1           2     -1.0        -1  \n",
       "\n",
       "[30461 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655ccf7-9e37-414b-89ca-89fa3ea1e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_all[['TOTEXP18', 'AGE42X', 'ADBMI42', 'MNHLTH42']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bafdc-1467-464e-8f1a-1a32b97d986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f00dff-f5b4-41d0-a634-97685533758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices('TOTEXP18 ~ AGE42X + ADBMI42 + MNHLTH42', data=df_train, return_type='dataframe')\n",
    "# y_test, X_test = dmatrices('FE ~ EngDispl', data=df_test, return_type='dataframe')\n",
    "# y_conf, X_conf = dmatrices('FE ~ EngDispl', data=df_test, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377313c8-a057-4359-b184-a14c47edb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed15c07-a3b8-4e66-aa00-ce86ee47bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1480a-4173-4f3b-9922-f24f19c2363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.AGE42X, y.TOTEXP18, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a9d11-e3d3-47a9-b934-4daecabf997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistically confirm that the data is(/not) heteroscedastic\n",
    "\n",
    "ols = sm.OLS(y, X)\n",
    "ols_result = ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f575e2-655c-4150-9cac-dce9685628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_result.mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cbfd6-a80c-42de-a6ab-4c20ffd9e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals of a LM are dependent on X\n",
    "# plt.scatter(X.EngDispl, ols_result.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a2046-7e2b-490f-ba7b-8a608c00ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical tests confirm this:\n",
    "het_white(ols_result.resid, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0189e-f884-47ed-83f8-80e777aade05",
   "metadata": {},
   "outputs": [],
   "source": [
    "het_breuschpagan(ols_result.resid, X, robust=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fa604-f83c-4f14-820a-71fc60a98bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a096b-2cc3-4a49-83ab-7475aafb795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch = torch.from_numpy(X.to_numpy())[:, 1:] #.unsqueeze(-1)\n",
    "y_torch = torch.from_numpy(y.to_numpy()).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88040c94-70fa-461b-96ed-35b5a90de6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155c8f2-8548-4efe-9828-2b72226e3f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = int(.1 * len(X_torch))\n",
    "X_test, X_train = X_torch[-n_test:], X_torch[:-n_test]\n",
    "y_test, y_train = y_torch[-n_test:], y_torch[:-n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d60d3-d92c-406c-99ce-efc72d879307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs\n",
    "mu = X_train.mean(dim=0)\n",
    "std = torch.norm(X_train - mu, dim=0)\n",
    "# mu\n",
    "# # std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be7e7c-14bc-4276-aacb-ed0d403e93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - mu) / std\n",
    "X_test = (X_test - mu) / std\n",
    "# X_torch = (X_torch - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba274a-2f3a-4ac3-b324-0beb354523ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f8f36-0b8e-42df-9e79-0af1a0963827",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch[:100, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d95da3-6080-4e19-8dd5-be6412993c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_plot(model):\n",
    "    alpha = model.alpha\n",
    "    model.eval()\n",
    "    \n",
    "    # t = torch.linspace(X_torch[:, 1].min(), X_torch[:, 1].max() +0.1 , 100).unsqueeze(-1)\n",
    "    # print(t.shape)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        y_pred, sigma_sq = model(X_train[:200,:])\n",
    "        std_pred = sigma_sq.sqrt()\n",
    "    \n",
    "    # t = t.squeeze().numpy()\n",
    "    y_pred = y_pred.squeeze().numpy()\n",
    "    std_pred = std_pred.squeeze().numpy()\n",
    "\n",
    "    if alpha == 1:\n",
    "        # 95% confidence interval.\n",
    "        a = 2*std_pred\n",
    "    else:\n",
    "        # 100% confidence interval.\n",
    "        R = _radius(1, alpha)\n",
    "        tau = (-R**2)/2 * (std_pred**2) ** (-(alpha-1) / (alpha+1))\n",
    "        a = np.sqrt(-2 * tau * std_pred**2)\n",
    "        \n",
    "    return X_train[:200,0], y_pred, a\n",
    "    \n",
    "\n",
    "def plot_model(t, y_pred, a, ax, which=\"support\", fill_color='C0'):\n",
    "    ax.plot(t, y_pred, color='C0', label=\"predicted mean\")\n",
    "\n",
    "    ax.fill_between(t,\n",
    "                    y_pred - a,\n",
    "                    y_pred + a,\n",
    "                    alpha=0.2, color=fill_color, label=\"predicted {}\".format(which))\n",
    "       \n",
    "    # Plot the truth\n",
    "    ax.scatter(((X_train[:200,1]+X_train[:200,0]+X_train[:200,2])/3).squeeze().numpy(), y_train[:200].squeeze().numpy(), marker='.', color='C1', label='train')\n",
    "    # ax.scatter(X_test.squeeze().numpy(), y_test.squeeze().numpy(), marker='x', color='C2', label='test')\n",
    "\n",
    "    # ax.set_ylim(-10, 370)\n",
    "    ax.set_xlim(None, t[-1])\n",
    "    \n",
    "def save_for_conf(model):\n",
    "    alpha = model.alpha\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        y_pred_test, sigma_sq_test = model(X_test)\n",
    "        std_pred_test = sigma_sq_test.sqrt()\n",
    "    \n",
    "    y_pred_test = y_pred_test.squeeze().numpy()\n",
    "    std_pred_test = std_pred_test.squeeze().numpy()\n",
    "\n",
    "    if alpha == 1:\n",
    "        # 95% confidence interval.\n",
    "        a_test = 2*std_pred_test\n",
    "    else:\n",
    "        # 100% confidence interval.\n",
    "        R_test = _radius(1, alpha)\n",
    "        tau_test = (-R_test**2)/2 * (std_pred_test**2) ** (-(alpha-1) / (alpha+1))\n",
    "        a_test = np.sqrt(-2 * tau_test * std_pred_test**2)\n",
    "\n",
    "    # t_conf = torch.linspace(X_conf.min(), X_conf.max() + .1, len(X_conf)).unsqueeze(-1)\n",
    "    # with torch.no_grad():\n",
    "    \n",
    "    #     y_pred_conf, sigma_sq_conf = model(t_conf)\n",
    "    #     std_pred_conf = sigma_sq_conf.sqrt()\n",
    "    \n",
    "    # t_conf = t_conf.squeeze().numpy()\n",
    "    # y_pred_conf = y_pred_conf.squeeze().numpy()\n",
    "    # std_pred_conf = std_pred_conf.squeeze().numpy()\n",
    "\n",
    "    # if alpha == 1:\n",
    "    #     # 95% confidence interval.\n",
    "    #     a_conf = 2*std_pred_conf\n",
    "    # else:\n",
    "    #     # 100% confidence interval.\n",
    "    #     R_conf = _radius(1, alpha)\n",
    "    #     tau_conf = (-R_conf**2)/2 * (std_pred_conf**2) ** (-(alpha-1) / (alpha+1))\n",
    "    #     a_conf = np.sqrt(-2 * tau_conf * std_pred_conf**2)\n",
    "    return y_test, y_pred_test, a_test, #y_conf, y_pred_conf, a_conf\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7f0ae-01bd-4bd7-b94a-9c146ead6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, 1].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccb33d-d1d6-4f74-b226-658ef8f47eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "\n",
    "torch.manual_seed(42)\n",
    "bl_model = BetaGaussianLM(input_size=3, uncertainty=False, heteroscedastic=False, alpha=None)\n",
    "optimizer = torch.optim.LBFGS(bl_model.parameters(), lr=.01, max_iter=100)\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        bl_model.train()\n",
    "        loss = bl_model.loss(X_train, y_train)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "# evaluate R^2\n",
    "y_pred_train = bl_model.predict(X_train).detach().numpy()\n",
    "y_pred_test = bl_model.predict(X_test).detach().numpy()\n",
    "print(\"R2 train {:.3f} test {:.3f}\".format(\n",
    "    r2_score(y_pred_train, y_train.numpy()),\n",
    "    r2_score(y_pred_test, y_test.numpy())))\n",
    "    \n",
    "print(\"w\", bl_model.pred_y.weight.data, \"b\", bl_model.pred_y.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe666b-163c-4e6c-b6b8-4d4d1b0d4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lbfgs\n",
    "\n",
    "old_loss = np.inf\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "results = []\n",
    "\n",
    "for j, alpha in enumerate([1, 4/3, 1.5, 2]):\n",
    "    for seed in [42,  ]: # 43, 44, 45, 46\n",
    "        torch.manual_seed(seed)\n",
    "        model = BetaGaussianLM(input_size=3, uncertainty=True, heteroscedastic=True, alpha=alpha)\n",
    "\n",
    "        model.pred_y.weight.data[:] = bl_model.pred_y.weight\n",
    "        model.pred_y.bias.data[:] = bl_model.pred_y.bias\n",
    "        \n",
    "        # model.lin.weight.data[:] = bl_model.lin.weight\n",
    "        # model.lin.bias.data[:] = bl_model.lin.bias\n",
    "        # model.quad.weight.data[:] = bl_model.quad.weight\n",
    "        # model.quad.bias.data[:] = bl_model.quad.bias\n",
    "        optimizer = torch.optim.LBFGS(model.parameters(), lr=.01, line_search_fn='strong_wolfe', max_iter=100)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                model.train()\n",
    "                loss = model.loss(X_train, y_train)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            \n",
    "            optimizer.step(closure)\n",
    "                \n",
    "        # evaluate R^2\n",
    "        model.eval()\n",
    "        y_pred_train = model.predict(X_train).detach().numpy()\n",
    "        y_pred_test = model.predict(X_test).detach().numpy()\n",
    "    \n",
    "        r2 = \"R2 train {:.3f} test {:.3f}\".format(\n",
    "            r2_score(y_pred_train, y_train.numpy()),\n",
    "            r2_score(y_pred_test, y_test.numpy()))\n",
    "    \n",
    "        results.append((alpha, save_for_plot(model), r2)) #\n",
    "        np.savetxt(f\"{alpha}_{seed}_{r2}.csv\", save_for_conf(model), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8acd4-65fc-4c74-97c8-8e326ab5a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[0][1][0]), len(results[0][1][1]), len(results[0][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c34173-c606-42f9-af52-ec36d08c030d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65cc64f-6311-4b90-989a-0ec21fd2c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_gauss, ax_tp) = plt.subplots(1, 2, figsize=(13, 4), constrained_layout=True)\n",
    "\n",
    "plt.rcParams['legend.title_fontsize'] = 15\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "plot_model(*results[0][1], ax_gauss, \"95% CI\", fill_color='C0')\n",
    "plot_model(*results[3][1], ax_tp, \"support\", fill_color='C8')\n",
    "ax_gauss.legend(title=\"Gaussian ($\\\\alpha=1$)\\n$r^2=$\", fontsize=15)\n",
    "ax_tp.legend(title=\"Truncated Parabola ($\\\\alpha=2$)\\n$r^2=$\", fontsize=15)\n",
    "ax_gauss.set_ylabel(\"TOTEXP18\", fontsize=15)\n",
    "ax_gauss.set_xlabel(\"ADBMI42\", fontsize=15)\n",
    "ax_tp.set_xlabel(\"ADBMI42\", fontsize=15)\n",
    "# plt.savefig(\"heteroscedastic.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afec3e-2e50-4007-bf21-4d528b617a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
