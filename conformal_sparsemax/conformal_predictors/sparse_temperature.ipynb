{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb435ae2-c3cc-4290-9f54-e2f83655fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from entmax import sparsemax,entmax15\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3cfab99-90b0-48db-b970-ad947b9af7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../../')\n",
    " \n",
    "# importing\n",
    "from conformal_sparsemax import ConformalPredictor, SparseScore, SoftmaxScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "422f221c-6a4e-4332-9965-03189f62d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-conformity scores\n",
    "#alpha = 0.1\n",
    "pred_cal_path = '../../predictions/CIFAR10_cal_FYLoss_softmax_proba.pickle'\n",
    "pred_test_path = '../../predictions/CIFAR10_test_FYLoss_softmax_proba.pickle'\n",
    "true_cal_path = '../../predictions/CIFAR10_cal_true.pickle'\n",
    "true_test_path = '../../predictions/CIFAR10_test_true.pickle'\n",
    "\n",
    "def get_data(pred_cal_path, pred_test_path,true_cal_path, true_test_path):\n",
    "    with open(pred_cal_path, 'rb') as f:\n",
    "        pred_cal = pickle.load(f)\n",
    "    with open(pred_test_path, 'rb') as f:\n",
    "        pred_test = pickle.load(f)\n",
    "    with open(true_cal_path, 'rb') as f:\n",
    "        true_cal = pickle.load(f)\n",
    "    with open(true_test_path, 'rb') as f:\n",
    "        true_test = pickle.load(f)\n",
    "    return pred_cal, pred_test, true_cal, true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4261fd4-663e-4c40-bf9a-9a801edca440",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_pred, test_pred, cal_true, test_true = get_data(pred_cal_path, \n",
    "                                                    pred_test_path,\n",
    "                                                    true_cal_path, \n",
    "                                                    true_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fc7a576-aa04-4377-986a-5f8867721e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2133, 0.9055)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = ConformalPredictor(SoftmaxScore())\n",
    "cp.calibrate(cal_true, cal_pred, 0.1)\n",
    "cp.evaluate(test_pred, test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941ea807-0eb0-4ba5-9288-6ae991b57a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.predict(test_pred).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a197a87-86f2-4d54-92af-f18977daad2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mConformalPredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConformalPredictor\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ...ConformalPredictor import ConformalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b47b923-c563-4dba-b5fa-ba8266f673fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cal, pred_test, true_cal, true_test = get_data(pred_cal_path, \n",
    "                                                    pred_test_path,\n",
    "                                                    true_cal_path, \n",
    "                                                    true_test_path)\n",
    "n_test = pred_test.shape[0]\n",
    "n_cal, n_classes = pred_cal.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12ad843-4ae2-4547-9c30-656a49d0975f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m true_mask \u001b[38;5;241m=\u001b[39m true_cal\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m      3\u001b[0m cal_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pred_cal[true_mask]\n\u001b[0;32m----> 5\u001b[0m q_level \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mceil((n_cal\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43malpha\u001b[49m))\u001b[38;5;241m/\u001b[39mn_cal\n\u001b[1;32m      6\u001b[0m qhat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mquantile(cal_scores, q_level, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# check quantile method\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# test scores\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# Get calibration quantile\n",
    "true_mask = true_cal.astype(bool)\n",
    "cal_scores = 1 - pred_cal[true_mask]\n",
    "\n",
    "q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal\n",
    "qhat = np.quantile(cal_scores, q_level, method = 'higher') # check quantile method\n",
    "\n",
    "# test scores\n",
    "test_scores = 1 - pred_test\n",
    "#alternative\n",
    "#test_scores = ((1 - pred_test)/(n_classes-pred_test.astype(bool).sum(axis=1).reshape((n_test,1))))\n",
    "# qhat = test_scores<= qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95e2e33-3acf-4f8c-8170-3b85c828a3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqhat\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qhat' is not defined"
     ]
    }
   ],
   "source": [
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46179ae3-490a-4ab8-87e2-f3026688fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(pred_test,true_test):\n",
    "    ranks = np.flip(pred_test.argsort(axis = 1),axis = 1).argsort()\n",
    "    match = np.select(true_test.astype(bool).T,ranks.T)\n",
    "    cond = ranks>np.expand_dims(match, axis=-1)\n",
    "    k_y = np.select(true_test.astype(bool).T,pred_test.T)\n",
    "    output = (pred_test-np.expand_dims(k_y, axis=-1))\n",
    "    output[cond] = 0\n",
    "    return np.linalg.norm(output,axis = 1, ord = 2)#output.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f88a5822-bb9f-462d-98e6-ff238346ea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96997035, 0.97045016, 0.97047937, ..., 0.9704219 , 0.9704451 ,\n",
       "        0.9704339 ],\n",
       "       [0.9997893 , 0.9996194 , 0.9997997 , ..., 0.99979955, 0.        ,\n",
       "        0.9997919 ],\n",
       "       [0.99998856, 0.9999894 , 0.99999124, ..., 0.9999915 , 0.        ,\n",
       "        0.9999914 ],\n",
       "       ...,\n",
       "       [0.9997524 , 0.9997524 , 0.9997495 , ..., 0.9995752 , 0.99975216,\n",
       "        0.9997514 ],\n",
       "       [0.9999583 , 0.        , 0.99995893, ..., 0.99995905, 0.9999592 ,\n",
       "        0.99995893],\n",
       "       [0.99997723, 0.9999855 , 0.9999854 , ..., 0.        , 0.99998444,\n",
       "        0.9999857 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_custom_scores(pred_test):\n",
    "    output = []\n",
    "    for i in range(pred_test.shape[1]):\n",
    "        true_test = np.zeros(pred_test.shape)\n",
    "        true_test[:,i] = 1\n",
    "        output.append(custom_score(pred_test,true_test)[None,:])\n",
    "    return np.concatenate(output,axis=0).T\n",
    "all_custom_scores(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff8d2545-8a2f-4242-9195-8cd5f3ac1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cp(pred_cal, pred_test, true_cal, true_test, alpha, plots = False, disallow_empty=False):\n",
    "    def get_pvalue(preds):\n",
    "                return np.array([((cal_scores>= el).sum() + 1)/(len(cal_scores) + 1) for el in preds])\n",
    "\n",
    "    n_cal, n_classes = pred_cal.shape \n",
    "    n_test = true_test.shape[0]\n",
    "    q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal\n",
    "    qhat = np.quantile(custom_score(pred_cal,true_cal), q_level, method = 'higher') # check quantile method\n",
    "    # Softmax\n",
    "    test_scores = all_custom_scores(pred_test)\n",
    "    test_match = test_scores<= qhat\n",
    "    \n",
    "    if disallow_empty:\n",
    "        helper = np.zeros(pred_test[(test_match.sum(axis = 1)==0)].shape)\n",
    "        helper[np.arange(helper.shape[0]),pred_test[(test_match.sum(axis = 1)==0)].argmax(axis = 1)]=1\n",
    "        test_match[(test_match.sum(axis = 1)==0)] = helper\n",
    "    # get p-values \n",
    "    test_pvalues = np.apply_along_axis(get_pvalue,1,test_scores)\n",
    "    p_values_cal = get_pvalue(cal_scores)\n",
    "    \n",
    "    # Set size and scores distribution\n",
    "    set_size = test_match.sum(axis = 1)\n",
    "    if plots:   \n",
    "        fig, axs = plt.subplots(1,2,figsize=(12,6))\n",
    "        axs[0].hist(set_size)\n",
    "        axs[0].vlines(set_size.mean(),0,max(np.histogram(set_size, bins=10)[0])+10, color='black')\n",
    "        axs[0].text(set_size.mean()*1.02,max(np.histogram(set_size, bins=10)[0]-10)*0.95,  f'S = {set_size.mean()}', color='black',fontweight='bold')\n",
    "        axs[0].set_title('Set Size Distribution')\n",
    "        \n",
    "        axs[1].hist(cal_scores)\n",
    "        axs[1].vlines(qhat,0,max(np.histogram(cal_scores, bins=10)[0])+10, color='black')\n",
    "        axs[1].text(qhat*1.02,max(np.histogram(cal_scores, bins=10)[0]-10)*0.95, f'q={qhat:.3f}', color='black',fontweight='bold')\n",
    "        axs[1].set_title('Non-Conf Scores Distribution')\n",
    "        plt.show()\n",
    "    \n",
    "    coverage = test_match[true_test.astype(bool)].sum()/n_test\n",
    "    #print(f'Coverage:{coverage}')\n",
    "    class_coverage = (test_match & true_test).sum(axis = 0)/true_test.sum(axis=0)\n",
    "    \n",
    "    set_size = test_match.sum(axis = 1)\n",
    "    #print(f'Avg set size:{set_size.mean()}')\n",
    "    class_size = true_test.copy()\n",
    "    class_size[class_size==1]=test_match.sum(axis = 1)\n",
    "    class_size = class_size.sum(axis=0)/true_test.sum(axis=0)\n",
    "    \n",
    "    if plots:\n",
    "        # Class-wise metrics\n",
    "        fig, axs = plt.subplots(1,2,figsize=(12,6))\n",
    "        # add labels?\n",
    "        axs[0].bar(np.arange(n_classes),class_coverage)\n",
    "        axs[0].hlines(coverage,0,n_classes-1, color='black')\n",
    "        axs[0].hlines(1-alpha,0,n_classes-1, color='green')\n",
    "        axs[0].text(0,coverage, f'Emp. cov. = {coverage:.2f}', color='black',fontweight='bold')\n",
    "        axs[0].text(0,1-alpha, f'Theo. cov. = {1-alpha:.2f}', color='green',fontweight='bold')\n",
    "        axs[0].set_title('Class Conditional Coverage')\n",
    "        \n",
    "        \n",
    "        axs[1].bar(np.arange(n_classes),class_size)\n",
    "        axs[1].hlines(set_size.mean(),0,100, color='black')\n",
    "        axs[1].text(0,set_size.mean(), f'S={set_size.mean():.3f}', color='black',fontweight='bold')\n",
    "        axs[1].set_title('Class Avg Set size')\n",
    "        \n",
    "        plt.show()\n",
    "    # Observed fuzziness\n",
    "    of = np.ma.array(test_pvalues, mask = true_test).mean(axis=1).data.mean()\n",
    "    #print(f'OF={of:.4f}')\n",
    "    return test_match, coverage, set_size.mean(), qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c3f7db6-f37d-485b-83ab-a02e708a0258",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_match, coverage, mean_set_size, qhat \u001b[38;5;241m=\u001b[39m run_cp(pred_cal, pred_test, true_cal, true_test, \u001b[43malpha\u001b[49m, plots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(coverage, mean_set_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "test_match, coverage, mean_set_size, qhat = run_cp(pred_cal, pred_test, true_cal, true_test, alpha, plots = False)\n",
    "print(coverage, mean_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00559576-c022-48d3-98ff-cb6f312605e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7758 2.613\n"
     ]
    }
   ],
   "source": [
    "beta = 1/qhat\n",
    "sparse_pred = sparsemax(torch.tensor(pred_test)*beta, dim = -1)\n",
    "sparse_pred = sparse_pred.numpy()\n",
    "pred_match = sparse_pred>0\n",
    "coverage = pred_match[true_test.astype(bool)].sum()/n_test\n",
    "mean_set_size = pred_match.sum(axis = 1).mean()\n",
    "print(coverage, mean_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3e7365a4-e930-4928-ab1a-80039776e888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9018 40.2064\n"
     ]
    }
   ],
   "source": [
    "#ent\n",
    "beta = 2/qhat\n",
    "sparse_pred = entmax15(torch.tensor(pred_test)*beta, dim = -1)\n",
    "sparse_pred = sparse_pred.numpy()\n",
    "pred_match = sparse_pred>0\n",
    "coverage = pred_match[true_test.astype(bool)].sum()/n_test\n",
    "mean_set_size = pred_match.sum(axis = 1).mean()\n",
    "print(coverage, mean_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbeef6e-aba8-45fc-a07c-bc6bf3f98cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa5e95-edc8-466c-9631-3afdc3e1762a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
