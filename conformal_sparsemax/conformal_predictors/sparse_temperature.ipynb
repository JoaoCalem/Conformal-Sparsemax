{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb435ae2-c3cc-4290-9f54-e2f83655fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from entmax import sparsemax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "422f221c-6a4e-4332-9965-03189f62d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-conformity scores\n",
    "alpha = 0.1\n",
    "pred_cal_path = '../../predictions/CIFAR10_cal_NLLLoss_softmax_proba.pickle'\n",
    "pred_test_path = '../../predictions/CIFAR10_test_NLLLoss_softmax_proba.pickle'\n",
    "true_cal_path = '../../predictions/CIFAR10_cal_true.pickle'\n",
    "true_test_path = '../../predictions/CIFAR10_test_true.pickle'\n",
    "\n",
    "def get_data(pred_cal_path, pred_test_path,true_cal_path, true_test_path):\n",
    "    with open(pred_cal_path, 'rb') as f:\n",
    "        pred_cal = pickle.load(f)\n",
    "    with open(pred_test_path, 'rb') as f:\n",
    "        pred_test = pickle.load(f)\n",
    "    with open(true_cal_path, 'rb') as f:\n",
    "        true_cal = pickle.load(f)\n",
    "    with open(true_test_path, 'rb') as f:\n",
    "        true_test = pickle.load(f)\n",
    "    return pred_cal, pred_test, true_cal, true_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b47b923-c563-4dba-b5fa-ba8266f673fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cal, pred_test, true_cal, true_test = get_data(pred_cal_path, \n",
    "                                                    pred_test_path,\n",
    "                                                    true_cal_path, \n",
    "                                                    true_test_path)\n",
    "n_test = pred_test.shape[0]\n",
    "n_cal, n_classes = pred_cal.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f12ad843-4ae2-4547-9c30-656a49d0975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get calibration quantile\n",
    "true_mask = true_cal.astype(bool)\n",
    "cal_scores = 1 - pred_cal[true_mask]\n",
    "\n",
    "q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal\n",
    "qhat = np.quantile(cal_scores, q_level, method = 'higher') # check quantile method\n",
    "\n",
    "# test scores\n",
    "test_scores = 1 - pred_test\n",
    "#alternative\n",
    "#test_scores = ((1 - pred_test)/(n_classes-pred_test.astype(bool).sum(axis=1).reshape((n_test,1))))\n",
    "# qhat = test_scores<= qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b95e2e33-3acf-4f8c-8170-3b85c828a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8544148"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "46179ae3-490a-4ab8-87e2-f3026688fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(pred_test,true_test):\n",
    "    ranks = np.flip(pred_test.argsort(axis = 1),axis = 1).argsort()\n",
    "    match = np.select(true_test.astype(bool).T,ranks.T)\n",
    "    cond = ranks>np.expand_dims(match, axis=-1)\n",
    "    k_y = np.select(true_test.astype(bool).T,pred_test.T)\n",
    "    output = (pred_test-np.expand_dims(k_y, axis=-1))\n",
    "    output[cond] = 0\n",
    "    return output.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f88a5822-bb9f-462d-98e6-ff238346ea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99833435, 0.9997803 , 0.9999998 , ..., 0.9996498 , 0.9997507 ,\n",
       "        0.9996964 ],\n",
       "       [0.9999592 , 0.9996194 , 1.0000001 , ..., 0.9999988 , 0.        ,\n",
       "        0.9999671 ],\n",
       "       [0.99998856, 0.9999903 , 0.9999967 , ..., 0.9999982 , 0.        ,\n",
       "        0.99999785],\n",
       "       ...,\n",
       "       [0.99999934, 0.9999993 , 0.9999837 , ..., 0.9995752 , 0.9999977 ,\n",
       "        0.99999326],\n",
       "       [0.9999949 , 0.        , 0.9999971 , ..., 0.9999978 , 0.99999833,\n",
       "        0.9999969 ],\n",
       "       [0.99997723, 0.9999985 , 0.999998  , ..., 0.        , 0.99999416,\n",
       "        0.9999998 ]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_custom_scores(pred_test):\n",
    "    output = []\n",
    "    for i in range(pred_test.shape[1]):\n",
    "        true_test = np.zeros(pred_test.shape)\n",
    "        true_test[:,i] = 1\n",
    "        output.append(custom_score(pred_test,true_test)[None,:])\n",
    "    return np.concatenate(output,axis=0).T\n",
    "all_custom_scores(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ff8d2545-8a2f-4242-9195-8cd5f3ac1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_cp(pred_cal, pred_test, true_cal, true_test, alpha, plots = False, disallow_empty=False):\n",
    "    def get_pvalue(preds):\n",
    "                return np.array([((cal_scores>= el).sum() + 1)/(len(cal_scores) + 1) for el in preds])\n",
    "\n",
    "    n_cal, n_classes = pred_cal.shape \n",
    "    n_test = true_test.shape[0]\n",
    "    q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal\n",
    "    qhat = np.quantile(custom_score(pred_cal,true_cal), q_level, method = 'higher') # check quantile method\n",
    "    \n",
    "    test_scores = all_custom_scores(pred_test)\n",
    "    test_match = test_scores<= qhat\n",
    "    \n",
    "    if disallow_empty:\n",
    "        helper = np.zeros(pred_test[(test_match.sum(axis = 1)==0)].shape)\n",
    "        helper[np.arange(helper.shape[0]),pred_test[(test_match.sum(axis = 1)==0)].argmax(axis = 1)]=1\n",
    "        test_match[(test_match.sum(axis = 1)==0)] = helper\n",
    "    # get p-values \n",
    "    test_pvalues = np.apply_along_axis(get_pvalue,1,test_scores)\n",
    "    p_values_cal = get_pvalue(cal_scores)\n",
    "    \n",
    "    # Set size and scores distribution\n",
    "    set_size = test_match.sum(axis = 1)\n",
    "    if plots:   \n",
    "        fig, axs = plt.subplots(1,2,figsize=(12,6))\n",
    "        axs[0].hist(set_size)\n",
    "        axs[0].vlines(set_size.mean(),0,max(np.histogram(set_size, bins=10)[0])+10, color='black')\n",
    "        axs[0].text(set_size.mean()*1.02,max(np.histogram(set_size, bins=10)[0]-10)*0.95,  f'S = {set_size.mean()}', color='black',fontweight='bold')\n",
    "        axs[0].set_title('Set Size Distribution')\n",
    "        \n",
    "        axs[1].hist(cal_scores)\n",
    "        axs[1].vlines(qhat,0,max(np.histogram(cal_scores, bins=10)[0])+10, color='black')\n",
    "        axs[1].text(qhat*1.02,max(np.histogram(cal_scores, bins=10)[0]-10)*0.95, f'q={qhat:.3f}', color='black',fontweight='bold')\n",
    "        axs[1].set_title('Non-Conf Scores Distribution')\n",
    "        plt.show()\n",
    "    \n",
    "    coverage = test_match[true_test.astype(bool)].sum()/n_test\n",
    "    #print(f'Coverage:{coverage}')\n",
    "    class_coverage = (test_match & true_test).sum(axis = 0)/true_test.sum(axis=0)\n",
    "    \n",
    "    set_size = test_match.sum(axis = 1)\n",
    "    #print(f'Avg set size:{set_size.mean()}')\n",
    "    class_size = true_test.copy()\n",
    "    class_size[class_size==1]=test_match.sum(axis = 1)\n",
    "    class_size = class_size.sum(axis=0)/true_test.sum(axis=0)\n",
    "    \n",
    "    if plots:\n",
    "        # Class-wise metrics\n",
    "        fig, axs = plt.subplots(1,2,figsize=(12,6))\n",
    "        # add labels?\n",
    "        axs[0].bar(np.arange(n_classes),class_coverage)\n",
    "        axs[0].hlines(coverage,0,n_classes-1, color='black')\n",
    "        axs[0].hlines(1-alpha,0,n_classes-1, color='green')\n",
    "        axs[0].text(0,coverage, f'Emp. cov. = {coverage:.2f}', color='black',fontweight='bold')\n",
    "        axs[0].text(0,1-alpha, f'Theo. cov. = {1-alpha:.2f}', color='green',fontweight='bold')\n",
    "        axs[0].set_title('Class Conditional Coverage')\n",
    "        \n",
    "        \n",
    "        axs[1].bar(np.arange(n_classes),class_size)\n",
    "        axs[1].hlines(set_size.mean(),0,100, color='black')\n",
    "        axs[1].text(0,set_size.mean(), f'S={set_size.mean():.3f}', color='black',fontweight='bold')\n",
    "        axs[1].set_title('Class Avg Set size')\n",
    "        \n",
    "        plt.show()\n",
    "    # Observed fuzziness\n",
    "    of = np.ma.array(test_pvalues, mask = true_test).mean(axis=1).data.mean()\n",
    "    #print(f'OF={of:.4f}')\n",
    "    return test_match, coverage, set_size.mean(), qhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5c3f7db6-f37d-485b-83ab-a02e708a0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015 1.1326\n"
     ]
    }
   ],
   "source": [
    "test_match, coverage, mean_set_size, qhat = run_cp(pred_cal, pred_test, true_cal, true_test, alpha, plots = False)\n",
    "print(coverage, mean_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "00559576-c022-48d3-98ff-cb6f312605e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015 1.1326\n"
     ]
    }
   ],
   "source": [
    "beta = 1/qhat\n",
    "sparse_pred = sparsemax(torch.tensor(pred_test)*beta, dim = -1)\n",
    "sparse_pred = sparse_pred.numpy()\n",
    "pred_match = sparse_pred>0\n",
    "coverage = pred_match[true_test.astype(bool)].sum()/n_test\n",
    "mean_set_size = pred_match.sum(axis = 1).mean()\n",
    "print(coverage, mean_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7365a4-e930-4928-ab1a-80039776e888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
